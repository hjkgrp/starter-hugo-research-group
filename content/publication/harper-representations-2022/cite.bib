@article{harper_representations_2022,
 abstract = {Strategies for machine-learning (ML)-accelerated discovery that are general across material composition spaces are essential, but demonstrations of ML have been primarily limited to narrow composition variations. By addressing the scarcity of data in promising regions of chemical space for challenging targets such as open-shell transition-metal complexes, general representations and transferable ML models that leverage known relationships in existing data will accelerate discovery. Over a large set (âˆ¼1000) of isovalent transition-metal complexes, we quantify evident relationships for different properties (i.e., spin-splitting and ligand dissociation) between rows of the Periodic Table (i.e., 3d/4d metals and 2p/3p ligands). We demonstrate an extension to the graph-based revised autocorrelation (RAC) representation (i.e., eRAC) that incorporates the group number alongside the nuclear charge heuristic that otherwise overestimates dissimilarity of isovalent complexes. To address the common challenge of discovery in a new space where data are limited, we introduce a transfer learning approach in which we seed models trained on a large amount of data from one row of the Periodic Table with a small number of data points from the additional row. We demonstrate the synergistic value of the eRACs alongside this transfer learning strategy to consistently improve model performance. Analysis of these models highlights how the approach succeeds by reordering the distances between complexes to be more consistent with the Periodic Table, a property we expect to be broadly useful for other material domains.},
 author = {Harper, Daniel R. and Nandy, Aditya and Arunachalam, Naveen and Duan, Chenru and Janet, Jon Paul and Kulik, H. J.},
 doi = {10.1063/5.0082964},
 journal = {J. Chem. Phys.},
 pages = {074101},
 title = {Representations and Strategies for Transferable Machine Learning Improve Model Performance in Chemical Discovery},
 type = {Journal Article},
 url = {https://aip.scitation.org/doi/full/10.1063/5.0082964},
 volume = {156},
 year = {2022}
}

